#!/usr/bin/env python3
#	kartfire - Test framework to consistently run submission files
#	Copyright (C) 2023-2024 Johannes Bauer
#
#	This file is part of kartfire.
#
#	kartfire is free software; you can redistribute it and/or modify
#	it under the terms of the GNU General Public License as published by
#	the Free Software Foundation; this program is ONLY licensed under
#	version 3 of the License, later versions are explicitly excluded.
#
#	kartfire is distributed in the hope that it will be useful,
#	but WITHOUT ANY WARRANTY; without even the implied warranty of
#	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#	GNU General Public License for more details.
#
#	You should have received a copy of the GNU General Public License
#	along with kartfire; if not, write to the Free Software
#	Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
#	Johannes Bauer <JohannesBauer@gmx.de>

import os
import base64
import json
import sys
import time
import subprocess
import contextlib
import tempfile
import stat
import collections

if len(sys.argv) < 2:
	print(f"{sys.argv[0]}: No argument given.", file = sys.stderr)
	sys.exit(1)

class ContainerTestrunner():
	def __init__(self, config_filename: str):
		with open(config_filename) as f:
			self._config = json.load(f)
		with contextlib.suppress(FileExistsError):
			os.makedirs(self.meta["local_dut_dir"])
		self._tc_results = { }

	def logmsg(self, msg: str):
		if self.meta.get("debug"):
			print(msg, file = sys.stderr)

	@property
	def meta(self) -> dict:
		return self._config["meta"]

	@property
	def max_testbatch_size(self) -> int:
		return self.meta.get("max_testbatch_size", 1)

	@property
	def testcases(self) -> list[dict]:
		return self._config["testcases"]

	@property
	def testcase_count(self):
		return len(self.testcases)

	def _exec(self, cmd: list[str], timeout_secs: float):
		t0 = time.time()
		had_timeout = False
		exception_msg = None
		stdout = bytes()
		stderr = bytes()
		returncode = None
		try:
			result = subprocess.run(cmd, stdout = subprocess.PIPE, stderr = subprocess.PIPE, timeout = timeout_secs)
			stdout = result.stdout
			stderr = result.stderr
			returncode = result.returncode
			if returncode == -9:
				exception_msg = "Out of memory"
		except subprocess.TimeoutExpired as e:
			had_timeout = True
			exception_msg = f"{e.__class__.__name__} when trying execution: {str(e)}"
		except PermissionError as e:
			perms = stat.S_IMODE(os.stat(cmd[0]).st_mode)
			missing_exec = (perms & 0o111) == 0
			exception_msg = f"{e.__class__.__name__} when trying execution of {cmd[0]} (permissions {perms:#o}{' - missing execution bit!' if missing_exec else ''}): {str(e)}"
		except OSError as e:
			exception_msg = f"{e.__class__.__name__} when trying execution: {str(e)}"
		runtime_secs = time.time() - t0

		exec_result = {
			"stdout": stdout[-self.meta["limit_stdout_bytes"] : ],
			"stderr": stderr[-self.meta["limit_stdout_bytes"] : ],
			"stdout_length": len(stdout),
			"stderr_length": len(stderr),
			"returncode": returncode,
			"runtime_secs": runtime_secs,
			"timeout": had_timeout,
			"exception_msg": exception_msg,
		}
		self.logmsg(f"{cmd} exited: {exec_result}")
		return exec_result

	def _unpack_files(self):
		if "local_testcase_tar_file" in self.meta:
			subprocess.check_call([ "tar", "-x", "-C", self.meta["local_dut_dir"], "-f", self.meta["local_testcase_tar_file"] ])
		else:
			self.logmsg("No key 'local_testcase_tar_file' given, expecting DUT directory to already exist.")

	def _run_setup(self):
		setup_exec = f"{self.meta['local_dut_dir']}/{self.meta['setup_name']}"
		if os.path.exists(setup_exec):
			return self._exec([ setup_exec ], timeout_secs = self.meta["max_setup_time_secs"])
		else:
			return None

	def _run_testbatch(self, testbatch: list[dict], timeout_secs: float):
		with open(self.meta["local_testcase_filename"], "w") as f:
			local_json_content = {
				"testcases": { testcase["name"]: testcase["testcase_data"] for testcase in testbatch },
			}
			json.dump(local_json_content, f)
		solution_exec = f"{self.meta['local_dut_dir']}/{self.meta['solution_name']}"
		testbatch_results = self._exec([ solution_exec, self.meta["local_testcase_filename"] ], timeout_secs = timeout_secs)
		return {
			"testcases": [ testcase["name"] for testcase in testbatch ],
			"results": testbatch_results,
		}

	def _get_initial_testbatches(self):
		"""Split testbatches into groups of maximum size initially."""
		for i in range(0, self.testcase_count, self.max_testbatch_size):
			yield self.testcases[i : i + self.max_testbatch_size]

	def _compute_allowance_secs(self, testbatch: list[dict]):
		return sum(testcase["runtime_allowance_secs"] for testcase in testbatch)

	def _recursive_run_testbatch(self, testbatch: list[dict], runtime_allowance_secs: float):
		result = [ ]
		self.logmsg(f"Running testbatch of {len(testbatch)} testcases given a time contingent of {runtime_allowance_secs:.1f} seconds.")

		t0 = time.time()
		batch_result = self._run_testbatch(testbatch, timeout_secs = runtime_allowance_secs)
		t1 = time.time()

		# Was the run successful or was it a single case?
		if (batch_result["results"]["returncode"] == 0) or (len(testbatch) < 2):
			# Record results
			result.append(batch_result)
		else:
			# Whole batch failed: bisect array, subtracting previously taken time from contingent
			already_taken_time_secs = t1 - t0
			remaining_allowance_secs = runtime_allowance_secs - already_taken_time_secs
			self.logmsg(f"Testbatch failed, wasted {already_taken_time_secs:.1f} secs without any answer to {len(testbatch)} testcases. {remaining_allowance_secs:.1f} secs remaining.")

			original_allowance_secs = self._compute_allowance_secs(testbatch)
			if remaining_allowance_secs > (original_allowance_secs / 2):
				half_index = len(testbatch) // 2
				left = testbatch[ : half_index]
				right = testbatch[half_index : ]

				subordinate_scalar = remaining_allowance_secs / original_allowance_secs
				left_allowance_secs = self._compute_allowance_secs(left) * subordinate_scalar
				right_allowance_secs = self._compute_allowance_secs(right) * subordinate_scalar
				self.logmsg(f"Bisecting previous batch of {len(testbatch)} testcases, subtracting {already_taken_time_secs:.1f} additional secs from time contingent, splitting into {len(left)} and {len(right)} testcases. Subordinate batches allowed {left_allowance_secs:.1f} secs/{right_allowance_secs:.1f} secs.")
				result += self._recursive_run_testbatch(left, left_allowance_secs)
				result += self._recursive_run_testbatch(right, right_allowance_secs)
			else:
				# No more time to further bisect, return failed batch result
				self.logmsg(f"Bisecting further impossible, not enough time contingent left.")
				result.append(batch_result)
		return result

	def run(self):
		t0 = time.time()
		result = {
			"setup": None,
			"testcase_results": [ ],
		}
		self._unpack_files()
		result["setup"] = self._run_setup()
		if (result["setup"] is not None) and (result["setup"]["returncode"] != 0):
			self.logmsg(f"Build failed, refusing to run any testcases.")
			result["testcase_results"].append({
				"testcases": [ testcase["name"] for testcase in self.testcases ],
				"results": {
					"exception_msg": "build failed, testrun skipped"
				}
			})
		else:
			for testbatch in self._get_initial_testbatches():
				runtime_allowance_secs = self._compute_allowance_secs(testbatch)
				result["testcase_results"] += self._recursive_run_testbatch(testbatch, runtime_allowance_secs = runtime_allowance_secs)
			result["runtime_secs"] = time.time() - t0
		return result

def serializer(obj):
	if isinstance(obj, bytes):
		return base64.b64encode(obj).decode("ascii")
	elif isinstance(obj, enum.Enum):
		return obj.value
	else:
		raise TypeError(obj)

config_filename = sys.argv[1]
ctr = ContainerTestrunner(config_filename)
result = ctr.run()
print(json.dumps(result, default = serializer))
