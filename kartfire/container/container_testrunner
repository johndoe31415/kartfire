#!/usr/bin/env python3
#	kartfire - Test framework to consistently run submission files
#	Copyright (C) 2023-2024 Johannes Bauer
#
#	This file is part of kartfire.
#
#	kartfire is free software; you can redistribute it and/or modify
#	it under the terms of the GNU General Public License as published by
#	the Free Software Foundation; this program is ONLY licensed under
#	version 3 of the License, later versions are explicitly excluded.
#
#	kartfire is distributed in the hope that it will be useful,
#	but WITHOUT ANY WARRANTY; without even the implied warranty of
#	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#	GNU General Public License for more details.
#
#	You should have received a copy of the GNU General Public License
#	along with kartfire; if not, write to the Free Software
#	Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
#	Johannes Bauer <JohannesBauer@gmx.de>

import os
import base64
import json
import sys
import time
import subprocess
import contextlib
import tempfile
import stat
import enum
import collections

if len(sys.argv) < 2:
	print(f"{sys.argv[0]}: No argument given.", file = sys.stderr)
	sys.exit(1)

class SubprocessExecutor():
	class ExecutionResult(enum.Enum):
		Success = "success"
		FailedReturnCode = "failed_return_code"
		FailedTimeout = "failed_timeout"
		FailedExecException = "failed_exec_exception"
		FailedNotExecutable = "failed_exec_not_executable"
		FailedOutOfMemory = "failed_oom"

	def __init__(self, cmd: list[str], maximum_runtime_secs: float, limit_stdout_bytes: int, limit_stderr_bytes: int):
		self._cmd = cmd
		self._maximum_runtime_secs = maximum_runtime_secs
		self._limit_stdout_bytes = limit_stdout_bytes
		self._limit_stderr_bytes = limit_stderr_bytes

	def run(self):
		result = {
			"cmd": self._cmd,
			"runtime_limit_secs": self._maximum_runtime_secs,
		}

		t0 = time.time()
		try:
			exec_result = subprocess.run(self._cmd, stdout = subprocess.PIPE, stderr = subprocess.PIPE, timeout = self._maximum_runtime_secs)
			result.update({
				"stdout": {
					"length": len(exec_result.stdout),
					"data": exec_result.stdout[:self._limit_stdout_bytes],
				},
				"stderr": {
					"length": len(exec_result.stderr),
					"data": exec_result.stderr[:self._limit_stderr_bytes],
				},
			})
			if exec_result.returncode == 0:
				result["status"] = self.ExecutionResult.Success
			elif exec_result.returncode == -9:
				result["status"] = self.ExecutionResult.FailedOutOfMemory
			else:
				result["status"] = self.ExecutionResult.FailedReturnCode
		except subprocess.TimeoutExpired as e:
			had_timeout = True
			exception_msg = f"{e.__class__.__name__} when trying execution: {str(e)}"
			result.update({
				"status": self.ExecutionResult.FailedReturnCode,
				"exception_msg": str(e),
			})
		except PermissionError as e:
			perms = stat.S_IMODE(os.stat(self._cmd[0]).st_mode)
			missing_exec = (perms & 0o111) == 0
			result.update({
				"status": self.ExecutionResult.FailedNotExecutable,
				"exception_msg": str(e),
				"perms": perms,
			})
		except OSError as e:
			result.update({
				"status": self.ExecutionResult.FailedExecException,
				"exception_msg": str(e),
			})
		result["runtime_secs"] = time.time() - t0
		return result


class ContainerTestrunner():
	def __init__(self, config_filename: str):
		with open(config_filename) as f:
			self._config = json.load(f)
		with contextlib.suppress(FileExistsError):
			os.makedirs(self.meta["local_dut_dir"])
		self._tc_results = { }

	def logmsg(self, msg: str):
		if self.meta.get("debug"):
			print(msg, file = sys.stderr)

	@property
	def meta(self) -> dict:
		return self._config["meta"]

	@property
	def max_testbatch_size(self) -> int:
		return self.meta.get("max_testbatch_size", 1)

	@property
	def testcases(self) -> list[dict]:
		return self._config["testcases"]

	@property
	def testcase_count(self):
		return len(self.testcases)

	def _unpack_files(self):
		if "local_testcase_tar_file" in self.meta:
			subprocess.check_call([ "tar", "-x", "-C", self.meta["local_dut_dir"], "-f", self.meta["local_testcase_tar_file"] ])
		else:
			self.logmsg("No key 'local_testcase_tar_file' given, expecting DUT directory to already exist.")

	def _run_setup(self):
		setup_exec = f"{self.meta['local_dut_dir']}/{self.meta['setup_name']}"
		if os.path.exists(setup_exec):
			return SubprocessExecutor(cmd = [ setup_exec ], maximum_runtime_secs = self.meta["max_setup_time_secs"], limit_stdout_bytes = self.meta["limit_stdout_bytes"], limit_stderr_bytes = self.meta["limit_stdout_bytes"]).run()
		else:
			return None

	def _run_testbatch(self, testbatch: list[dict], timeout_secs: float):
		with open(self.meta["local_testcase_filename"], "w") as f:
			local_json_content = {
				"testcases": { testcase["name"]: testcase["testcase_data"] for testcase in testbatch },
			}
			json.dump(local_json_content, f)
		solution_exec = f"{self.meta['local_dut_dir']}/{self.meta['solution_name']}"
		testbatch_results = SubprocessExecutor(cmd = [ solution_exec, self.meta["local_testcase_filename"] ], maximum_runtime_secs = timeout_secs, limit_stdout_bytes = self.meta["limit_stdout_bytes"], limit_stderr_bytes = self.meta["limit_stdout_bytes"]).run()
		return {
			"testcases": [ testcase["name"] for testcase in testbatch ],
			"process": testbatch_results,
		}

	def _get_initial_testbatches(self):
		"""Split testbatches into groups of maximum size initially."""
		for i in range(0, self.testcase_count, self.max_testbatch_size):
			yield self.testcases[i : i + self.max_testbatch_size]

	def _compute_allowance_secs(self, testbatch: list[dict]):
		return sum(testcase["runtime_allowance_secs"] for testcase in testbatch)

	def _recursive_run_testbatch(self, testbatch: list[dict], runtime_allowance_secs: float):
		result = [ ]
		self.logmsg(f"Running testbatch of {len(testbatch)} testcases given a time contingent of {runtime_allowance_secs:.1f} seconds.")

		t0 = time.time()
		batch_result = self._run_testbatch(testbatch, timeout_secs = runtime_allowance_secs)
		t1 = time.time()

		# Was the run successful or was it a single case?
		if (batch_result["process"]["status"] == SubprocessExecutor.ExecutionResult.Success) or (len(testbatch) <= 1):
			# Record results
			result.append(batch_result)
		else:
			# Whole batch failed: bisect array, subtracting previously taken time from contingent
			already_taken_time_secs = t1 - t0
			remaining_allowance_secs = runtime_allowance_secs - already_taken_time_secs
			self.logmsg(f"Testbatch failed, wasted {already_taken_time_secs:.1f} secs without any answer to {len(testbatch)} testcases. {remaining_allowance_secs:.1f} secs remaining.")

			original_allowance_secs = self._compute_allowance_secs(testbatch)
			if remaining_allowance_secs > (original_allowance_secs / 2):
				half_index = len(testbatch) // 2
				left = testbatch[ : half_index]
				right = testbatch[half_index : ]

				subordinate_scalar = remaining_allowance_secs / original_allowance_secs
				left_allowance_secs = self._compute_allowance_secs(left) * subordinate_scalar
				right_allowance_secs = self._compute_allowance_secs(right) * subordinate_scalar
				self.logmsg(f"Bisecting previous batch of {len(testbatch)} testcases, subtracting {already_taken_time_secs:.1f} additional secs from time contingent, splitting into {len(left)} and {len(right)} testcases. Subordinate batches allowed {left_allowance_secs:.1f} secs/{right_allowance_secs:.1f} secs.")
				result += self._recursive_run_testbatch(left, left_allowance_secs)
				result += self._recursive_run_testbatch(right, right_allowance_secs)
			else:
				# No more time to further bisect, return failed batch result
				self.logmsg(f"Bisecting further impossible, not enough time contingent left.")
				result.append(batch_result)
		return result

	def run(self):
		t0 = time.time()
		result = {
			"setup": None,
			"testcases": [ testcase["name"] for testcase in self.testcases ],
			"testbatches": [ ],
		}
		self._unpack_files()
		result["setup"] = self._run_setup()
		if (result["setup"] is not None) and (result["setup"]["status"] != SubprocessExecutor.ExecutionResult.Success):
			self.logmsg(f"Build failed, refusing to run any testcases.")
		else:
			for testbatch in self._get_initial_testbatches():
				runtime_allowance_secs = self._compute_allowance_secs(testbatch)
				result["testbatches"] += self._recursive_run_testbatch(testbatch, runtime_allowance_secs = runtime_allowance_secs)
			result["total_runtime_secs"] = time.time() - t0
		return result

def serializer(obj):
	if isinstance(obj, bytes):
		return base64.b64encode(obj).decode("ascii")
	elif isinstance(obj, enum.Enum):
		return obj.name
	else:
		raise TypeError(obj)

config_filename = sys.argv[1]
ctr = ContainerTestrunner(config_filename)
result = ctr.run()
print(json.dumps(result, default = serializer))
