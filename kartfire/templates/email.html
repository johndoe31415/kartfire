<%def name="possibly_link(text)">
%if text.startswith("http://") or text.startswith("https://"):
<a href="${text}">${text}</a>\
%else:
${text}\
%endif
</%def>\
<!doctype html>
<head>
	<style>
		body {
			font-family: sans-serif;
		}

		table {
			border-collapse: collapse;
			width: 100%;
			background: #ffffff;
		}

		th, td {
			border: 1px solid #dddddd;
			padding: 8px 12px;
			text-align: left;
			vertical-align: top;
		}

		th {
			background-color: #f0f0f0;
			font-weight: bold;
		}

		tr:nth-child(even) {
			background-color: #fafafa;
		}

		a {
			color: #0066cc;
			text-decoration: none;
		}

		p.hint {
			font-size: 75%;
			color: #444;
		}

		span.l {
			float: left;
		}

		span.r {
			float: right;
		}

		td.doubtful {
			color: #777;
		}
	</style>
</head>
<html><body>

<p>
%if m.solution_author is None:
Hallo,
%else:
Hallo ${m.solution_author},
%endif
</p>

<p>
anbei die Testergebnisse der Test-Pipeline, in der Ihre Lösung geprüft wurde.
</p>

<p>
<table>
	<tbody>
		<tr>
			<th>Multirun ID:</th>
			<td>${m.multirun_id}</td>
		</tr>
		<tr>
			<th>Getestete Abgabe:</th>
			<td>${m.source}</td>
		</tr>
		<tr>
			<th>Container:</th>
			<td>${m.env_meta["image"]["name"]}</td>
		</tr>
		<tr>
			<th>Container Quelle:</th>
			<td>${possibly_link(m.env_meta["image"]["source"])}</td>
		</tr>
		<tr>
			<th>Container Revision:</th>
			<td>${m.env_meta["image"]["revision"]}</td>
		</tr>
		<tr>
			<th>kartfire:</th>
			<td>${m.env_meta["kartfire"]}</td>
		</tr>
	</tbody>
</table>
</p>

%if m.overview["build_status"] == TestrunStatus.Finished:
<p>
Der Build-Step/Vorbereitungsschritt endete erfolgreich und war nach ${f"{m.build_runtime:d}"} beendet. Ergebnisse der durchgeführten Tests:
</p>

<p>
<table>
	<thead>
		<tr>
			<th>Run</th>
			<th>Collection</th>
			<th>LZ¹</th>
			<th>Ref¹</th>
			<th>Lim¹</th>
			<th>Testfälle</th>
			<th>Status</th>
			<th>Rel. LZ²</th>
			<th>Fehler</th>
		</tr>
	</thead>
	<tbody>
		%for run in m:
		<tr>
			<td>${run.run_id}</td>
			<td>${run.overview["collection"]}</td>
			<td>${f"{run.runtime:d}"}</td>
			<td>${f"{run.reference_runtime:d}"}</td>
			<td>${f"{run.runtime_allowance:d}"}</td>
			<td>${run.total_testcase_count}</td>
			<td>
				%if run.unique_status_result is None:
				😕
				%elif run.unique_status_result == TestresultStatus.Pass:
				🥳
				%else:
				😭
				%endif

				${run.status_text}
			</td>
			<td class="ralign${"" if run.unique_status_result == TestresultStatus.Pass else " doubtful"}">
				%if (run.relative_runtime is not None):
				<span class="l">
				%if run.relative_runtime < 0.25:
				🚀
				%elif run.relative_runtime < 1:
				🏎️
				%elif run.relative_runtime < 2:
				🚗
				%elif run.relative_runtime < 3:
				🚴
				%else:
				🐢
				%endif
				</span>
				<span class="r">${f'{100 * run.relative_runtime:.1f}'}%</span>
				%endif
			</td>
			<td>
				%if run.overview["error_details"] is None:
				—
				%else:
				${run.overview["error_details"]["text"]}
				%endif
			</td>
		</tr>
		%endfor
	</tbody>
</table>
</p>

<p class="hint">
¹: LZ = Laufzeit, Ref = Referenzlaufzeit, Lim = Erlaubte Maximalzeit Ihrer Lösung<br/>
²: Rel. LZ = Relative Laufzeit, d.h. Laufzeit verglichen mit der Referenzzeit. Weniger ist besser. Wert nur aussagekräftig, wenn alle Testcases erfolgreich durchlaufen.
</p>
%else:
<p>
Der Build-Schritt war nicht erfolgreich und war nach ${f"{m.build_runtime:d}"} beendet. Ihre Lösung konnte deshalb nicht getestet werden, alle Testcases werden als fehlgeschlagen gewertet: ${m.overview["build_status"].name}
</p>
%if m.overview["build_error_details"] is not None:
<p>
Weiterführende Fehlermeldung: ${m.overview["build_error_details"]["text"]}
</p>
%endif
%endif

<p>
Viel Erfolg weiterhin,<br/>
Ihre Kartfire CI/CD Pipeline
</p>
</body></html>
